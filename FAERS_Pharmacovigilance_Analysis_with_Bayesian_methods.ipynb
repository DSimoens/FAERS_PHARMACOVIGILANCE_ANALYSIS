{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdae8ee1-9bfc-4f1d-89ce-4367246cc891",
   "metadata": {},
   "source": [
    "# Pharmacovigilance Analysis using FAERS database and deduplication according to VigiMatch\n",
    "\n",
    "Version: 1  \n",
    "Author: Djamilla Simoens\n",
    "\n",
    "Please make sure your read the readme and work using a Python venv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2421bf87-ffdd-4b7a-826a-f9f7c1ecc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# 2) Import Following Libraries\n",
    "# =============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from scipy.stats import fisher_exact, chi2_contingency\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3464bfa8-bd7c-40ba-a4d8-fc84f1e5b0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell complete\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 3) User Input\n",
    "# =============================\n",
    "\n",
    "# Example input (replace by your own values)\n",
    "# Provide multiple names for drugs and adverse events\n",
    "\n",
    "drug_synonyms = ['capivasertib', 'TRUQAP']            # fill in quotes the drug of interest \n",
    "event_synonyms = ['Stomatitis', 'Aphthous Ulcer', 'Mouth Ulceration', 'Lip Ulceration', 'Glossodynia', 'Glossitis', 'Cheilitis', 'Oral Pain', 'Gingival Pain', 'Oral Discomfort', 'Oropharyngeal Pain']                       # fill in quots all adverse reactions of interest\n",
    "data_dir = './faers_data'                            # Update with your folder with the FAERS data, make sure you have .txt files\n",
    "output_file = 'FAERS_Rhopressa_vision_changes_Results.xlsx' # File name to write an Excel file to\n",
    "csv_log_output= \"csv_log_output.csv\"                  # File to write error logs to\n",
    "\n",
    "start_year_q = (2023, 4)                   # Year and quarter start\n",
    "end_year_q = (2025, 1)                     # Year and quarter end\n",
    "\n",
    "skipped_rows_log = []\n",
    "\n",
    "print(\"Cell complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6110a8de-004a-48bf-897b-40446b8c6811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading DRUG: 100%|███████████████████████████████| 6/6 [00:54<00:00,  9.16s/it]\n",
      "Loading REAC: 100%|███████████████████████████████| 6/6 [00:09<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DRUG records: 11665389\n",
      "Total REACTION records: 8727887\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Misc fuctions\n",
    "# =============================\n",
    "def is_in_range(fname, start, end):\n",
    "    import re\n",
    "    match = re.search(r'(\\d{2})(Q[1-4])', fname.upper())\n",
    "    if not match:\n",
    "        return False\n",
    "    year_str, quarter_str = match.groups()\n",
    "    year = int('20' + year_str) if int(year_str) < 50 else int('19' + year_str)\n",
    "    quarter = int(quarter_str[1])\n",
    "    return (year, quarter) >= start and (year, quarter) <= end\n",
    "\n",
    "# =============================\n",
    "# 4) Load FAERS Data\n",
    "# =============================\n",
    "\n",
    "def load_files(folder, pattern, start_range, end_range):\n",
    "    pattern_lower = pattern\n",
    "    pattern_upper = pattern.upper()\n",
    "    files = sorted(glob.glob(os.path.join(folder, pattern_lower)) +\n",
    "                   glob.glob(os.path.join(folder, pattern_upper)))\n",
    "\n",
    "    filtered_files = [f for f in files if is_in_range(os.path.basename(f), start_range, end_range)]\n",
    "\n",
    "    dfs = []\n",
    "    for file in tqdm(filtered_files, desc=f\"Loading {pattern.split('*')[0]}\"):\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                file,\n",
    "                sep='$',\n",
    "                dtype=str,\n",
    "                encoding='utf-8',\n",
    "                on_bad_lines='skip',\n",
    "                low_memory=False\n",
    "            )\n",
    "            dfs.append(df)\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                df = pd.read_csv(\n",
    "                    file,\n",
    "                    sep='$',\n",
    "                    dtype=str,\n",
    "                    encoding='latin1',\n",
    "                    on_bad_lines='skip',\n",
    "                    low_memory=False\n",
    "                )\n",
    "                dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {file}: {e}\")\n",
    "                skipped_rows_log.append((file, str(e)))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {file}: {e}\")\n",
    "            skipped_rows_log.append((file, str(e)))\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "df_drug = load_files(data_dir, 'DRUG*.txt', start_year_q, end_year_q)\n",
    "df_reac = load_files(data_dir, 'REAC*.txt', start_year_q, end_year_q)\n",
    "\n",
    "print(f\"Total DRUG records: {len(df_drug)}\")\n",
    "print(f\"Total REACTION records: {len(df_reac)}\")\n",
    "all_isr = set(df_drug['primaryid'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5551a25-93c4-4633-9944-b59e71aa5fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering suspect drugs...\n",
      "DRUG duplicates removed: 23308 (from 2494572 → 2471264)\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 5) Deduplication According to VigiMatch Standards\n",
    "# =============================\n",
    "\n",
    "print(\"Filtering suspect drugs...\")\n",
    "df_drug_ps = df_drug[df_drug['role_cod'].str.upper() == 'PS'].copy()\n",
    "df_drug_ps['drugname'] = df_drug_ps['drugname'].fillna('').str.upper()\n",
    "df_reac['pt'] = df_reac['pt'].fillna('').str.upper()\n",
    "\n",
    "def normalize_name(name):\n",
    "    if not isinstance(name, str):\n",
    "        return ''\n",
    "    name = name.upper()\n",
    "    for synonym in drug_synonyms:\n",
    "        if synonym.upper() in name:\n",
    "            return synonym.upper()\n",
    "    return name\n",
    "\n",
    "df_drug_ps['drugname_norm'] = df_drug_ps['drugname'].apply(normalize_name)\n",
    "\n",
    "dedup_columns = ['primaryid', 'drugname_norm', 'route', 'dose_vbm']\n",
    "for col in dedup_columns:\n",
    "    if col not in df_drug_ps.columns:\n",
    "        df_drug_ps[col] = ''\n",
    "\n",
    "df_drug_ps_before = len(df_drug_ps)\n",
    "df_drug_ps_unique = df_drug_ps.sort_values(by='primaryid').drop_duplicates(subset=dedup_columns)\n",
    "df_drug_ps_after = len(df_drug_ps_unique)\n",
    "duplicates_removed_drug = df_drug_ps_before - df_drug_ps_after\n",
    "\n",
    "print(f\"DRUG duplicates removed: {duplicates_removed_drug} (from {df_drug_ps_before} → {df_drug_ps_after})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a003ca-7a0e-4761-bb56-ee8c71079821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakdown of counts per event synonym:\n",
      "         Event Synonym  A (Drug+Event)  B (Drug+No Event)  C (Event+No Drug)  \\\n",
      "0           Stomatitis              13                989              10142   \n",
      "1       Aphthous Ulcer               0               1002               2568   \n",
      "2     Mouth Ulceration               0               1002               3320   \n",
      "3       Lip Ulceration               0               1002                114   \n",
      "4          Glossodynia               1               1001               4792   \n",
      "5            Glossitis               0               1002                419   \n",
      "6            Cheilitis               0               1002                729   \n",
      "7            Oral Pain               6                996               2771   \n",
      "8        Gingival Pain               1               1001               1024   \n",
      "9      Oral Discomfort               1               1001               1511   \n",
      "10  Oropharyngeal Pain               2               1000              15784   \n",
      "\n",
      "    D (Neither)  \n",
      "0       2424413  \n",
      "1       2431987  \n",
      "2       2431235  \n",
      "3       2434441  \n",
      "4       2429763  \n",
      "5       2434136  \n",
      "6       2433826  \n",
      "7       2431784  \n",
      "8       2433531  \n",
      "9       2433044  \n",
      "10      2418771  \n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 6) Matching Drug and Event (and synonym breakdown)\n",
    "# =============================\n",
    "\n",
    "# Build set of primaryids for drug synonyms\n",
    "isr_drug = set()\n",
    "for name in drug_synonyms:\n",
    "    name = name.upper()\n",
    "    matches = df_drug_ps_unique[df_drug_ps_unique['drugname_norm'] == name]['primaryid'].unique()\n",
    "    isr_drug.update(matches)\n",
    "    \n",
    "# Build set of primaryids for AE synonyms\n",
    "isr_event = set()\n",
    "for name in event_synonyms:\n",
    "    name = name.upper()\n",
    "    matches = df_reac[df_reac['pt'].str.contains(name, na=False, regex=False)]['primaryid'].unique()\n",
    "    isr_event.update(matches)\n",
    "\n",
    "\n",
    "# Event synonym breakdown - list all AE of interests and their specific count\n",
    "breakdown_list = []\n",
    "for event_term in event_synonyms:\n",
    "    event_term_upper = event_term.upper()\n",
    "    isr_event_term = set(df_reac[df_reac['pt'].str.contains(event_term_upper, na=False, regex=False)]['primaryid'].unique())\n",
    "    \n",
    "    A_term = len(isr_drug & isr_event_term)  # Drug + Event\n",
    "    B_term = len(isr_drug - isr_event_term)  # Drug + No Event\n",
    "    C_term = len(isr_event_term - isr_drug)  # Event + No Drug\n",
    "    D_term = len(all_isr - (isr_drug | isr_event_term))  # Neither\n",
    "    \n",
    "    breakdown_list.append({\n",
    "        'Event Synonym': event_term,\n",
    "        'A (Drug+Event)': A_term,\n",
    "        'B (Drug+No Event)': B_term,\n",
    "        'C (Event+No Drug)': C_term,\n",
    "        'D (Neither)': D_term\n",
    "    })\n",
    "\n",
    "breakdown_df = pd.DataFrame(breakdown_list)\n",
    "\n",
    "print(\"Breakdown of counts per event synonym:\")\n",
    "print(breakdown_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2033de38-f26b-4c61-b6f4-76e14687b60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table:\n",
      "A (Drug+Event): 24\n",
      "B (Drug+No Event): 978\n",
      "C (Event+No Drug): 37119\n",
      "D (Neither): 2397436\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 7) Build 2x2 Contingency Table\n",
    "# =============================\n",
    "\n",
    "A = len(isr_drug & isr_event)  # Drug + Event\n",
    "B = len(isr_drug - isr_event)  # Drug + No Event\n",
    "C = len(isr_event - isr_drug)  # Event + No Drug\n",
    "D = len(all_isr - (isr_drug | isr_event))  # Neither\n",
    "\n",
    "print(f\"Contingency Table:\\nA (Drug+Event): {A}\\nB (Drug+No Event): {B}\\nC (Event+No Drug): {C}\\nD (Neither): {D}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f71d06f9-767b-40b4-9fc0-0bcafec3d43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell calculation successful\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 8) Statistical Analysis\n",
    "# =============================\n",
    "\n",
    "# --- Classical Disproportionality Calculations ---\n",
    "contingency_table = np.array([[A, B], [C, D]])\n",
    "\n",
    "# ROR calculation\n",
    "ROR = (A / B) / (C / D) if B > 0 and C > 0 and D > 0 else np.nan\n",
    "\n",
    "# PRR calculation\n",
    "prr_numerator = A / (A + B) if (A + B) > 0 else np.nan\n",
    "prr_denominator = (A + C) / (A + B + C + D) if (A + B + C + D) > 0 else np.nan\n",
    "PRR = prr_numerator / prr_denominator if prr_denominator > 0 else np.nan\n",
    "\n",
    "# Fisher's exact test\n",
    "oddsr, p_fisher = fisher_exact(contingency_table)\n",
    "\n",
    "# Chi-square test without continuity correction\n",
    "chi2, p_chi2, dof, expected = chi2_contingency(contingency_table, correction=False)\n",
    "\n",
    "# Chi-square test with Yates continuity correction\n",
    "chi2_yates, p_chi2_yates, dof_yates, expected_yates = chi2_contingency(contingency_table, correction=True)\n",
    "\n",
    "# Standard Error and 95% CI for ROR\n",
    "SE = np.sqrt(1/A + 1/B + 1/C + 1/D) if A*B*C*D > 0 else np.nan\n",
    "lower_CI = np.exp(np.log(ROR) - 1.96 * SE) if not np.isnan(SE) else np.nan\n",
    "upper_CI = np.exp(np.log(ROR) + 1.96 * SE) if not np.isnan(SE) else np.nan\n",
    "\n",
    "# Standard Error and 95% CI for PRR\n",
    "if A > 0 and B > 0 and C > 0 and D > 0 and PRR > 0:\n",
    "    SE_log_PRR = np.sqrt(1/A - 1/(A+B) + 1/C - 1/(C+D))\n",
    "    lower_CI_PRR = np.exp(np.log(PRR) - 1.96 * SE_log_PRR)\n",
    "    upper_CI_PRR = np.exp(np.log(PRR) + 1.96 * SE_log_PRR)\n",
    "else:\n",
    "    lower_CI_PRR = np.nan\n",
    "    upper_CI_PRR = np.nan\n",
    "\n",
    "# Relative Reporting Ratio (RRR) and 95% CI\n",
    "if (A + B) > 0 and (C + D) > 0 and A > 0 and C > 0:\n",
    "    RRR = (A / (A + B)) / (C / (C + D))\n",
    "    SE_log_RRR = np.sqrt(1/A - 1/(A+B) + 1/C - 1/(C+D))\n",
    "    lower_CI_RRR = np.exp(np.log(RRR) - 1.96 * SE_log_RRR)\n",
    "    upper_CI_RRR = np.exp(np.log(RRR) + 1.96 * SE_log_RRR)\n",
    "else:\n",
    "    RRR = np.nan\n",
    "    lower_CI_RRR = np.nan\n",
    "    upper_CI_RRR = np.nan\n",
    "\n",
    "# Haldane's Odds Ratio (HOR) and 95% CI with 0.5 continuity correction\n",
    "a_c = A + 0.5\n",
    "b_c = B + 0.5\n",
    "c_c = C + 0.5\n",
    "d_c = D + 0.5\n",
    "HOR = (a_c * d_c) / (b_c * c_c)\n",
    "SE_log_HOR = np.sqrt(1/a_c + 1/b_c + 1/c_c + 1/d_c)\n",
    "lower_CI_HOR = np.exp(np.log(HOR) - 1.96 * SE_log_HOR)\n",
    "upper_CI_HOR = np.exp(np.log(HOR) + 1.96 * SE_log_HOR)\n",
    "\n",
    "# --- Bayesian Pharmacovigilance ---\n",
    "from scipy.stats import beta\n",
    "\n",
    "def bcpnn_ic(A, B, C, D, continuity=0.5, base=2.0):\n",
    "    N = A + B + C + D\n",
    "    if N == 0: return np.nan, np.nan, np.nan, np.nan\n",
    "    a_obs = A + continuity\n",
    "    E = ((A + B) * (A + C)) / N\n",
    "    E = E + continuity if E == 0 else E\n",
    "    ln_base = np.log(base)\n",
    "    ic = np.log(a_obs / E) / ln_base\n",
    "    var_ic = (1.0 / (ln_base ** 2)) * (1.0 / a_obs + 1.0 / E)\n",
    "    se = np.sqrt(var_ic)\n",
    "    return ic, var_ic, ic - 1.96*se, ic + 1.96*se\n",
    "\n",
    "def bayesian_prr(A, B, C, D, prior_a=1, prior_b=1, nsamples=50000):\n",
    "    rng = np.random.default_rng(42)\n",
    "    s1 = rng.beta(prior_a + A, prior_b + B, size=nsamples)\n",
    "    s2 = rng.beta(prior_a + C, prior_b + D, size=nsamples)\n",
    "    prr_samples = (s1+1e-12)/(s2+1e-12)\n",
    "    return {\n",
    "        \"mean\": np.mean(prr_samples),\n",
    "        \"median\": np.median(prr_samples),\n",
    "        \"ci_low\": np.percentile(prr_samples,2.5),\n",
    "        \"ci_high\": np.percentile(prr_samples,97.5),\n",
    "        \"p_gt1\": np.mean(prr_samples>1)\n",
    "    }\n",
    "\n",
    "def bayesian_ror(A, B, C, D, prior_a=0.5, prior_b=0.5, nsamples=50000):\n",
    "    rng = np.random.default_rng(123)\n",
    "    s1 = rng.beta(prior_a + A, prior_b + B, size=nsamples)\n",
    "    s2 = rng.beta(prior_a + C, prior_b + D, size=nsamples)\n",
    "    s1 = np.clip(s1, 1e-12, 1-1e-12)\n",
    "    s2 = np.clip(s2, 1e-12, 1-1e-12)\n",
    "    or_samples = (s1/(1-s1)) / (s2/(1-s2))\n",
    "    return {\n",
    "        \"mean\": np.mean(or_samples),\n",
    "        \"median\": np.median(or_samples),\n",
    "        \"ci_low\": np.percentile(or_samples,2.5),\n",
    "        \"ci_high\": np.percentile(or_samples,97.5),\n",
    "        \"p_gt1\": np.mean(or_samples>1)\n",
    "    }\n",
    "\n",
    "# Compute Bayesian metrics\n",
    "IC, IC_var, IC_low, IC_high = bcpnn_ic(A,B,C,D)\n",
    "prr_bayes = bayesian_prr(A,B,C,D)\n",
    "ror_bayes = bayesian_ror(A,B,C,D)\n",
    "\n",
    "print(\"Cell calculation successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d4bbf3-1612-4aff-a93b-ac9d7e18d5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Database               Drug(s)  \\\n",
      "0    FAERS  capivasertib, TRUQAP   \n",
      "\n",
      "                                            Event(s) Start Quarter  \\\n",
      "0  Stomatitis, Aphthous Ulcer, Mouth Ulceration, ...       Q4 2023   \n",
      "\n",
      "  End Quarter  A (Drug+Event)  B (Drug+No Event)  C (Event+No Drug)  \\\n",
      "0     Q1 2025              24                978              37119   \n",
      "\n",
      "   D (Neither)       ROR  ...  Bayesian PRR 95% CI Upper  \\\n",
      "0      2397436  1.584978  ...                   2.326003   \n",
      "\n",
      "   Bayesian PRR P(PRR>1)  Bayesian ROR Mean  Bayesian ROR Median  \\\n",
      "0                0.98688           1.618487             1.593959   \n",
      "\n",
      "   Bayesian ROR 95% CI Lower  Bayesian ROR 95% CI Upper  \\\n",
      "0                   1.037697                   2.332636   \n",
      "\n",
      "   Bayesian ROR P(ROR>1)  DRUG Duplicates Removed  Original DRUG Records  \\\n",
      "0                0.98302                    23308                2494572   \n",
      "\n",
      "   Skipped Files  \n",
      "0              0  \n",
      "\n",
      "[1 rows x 41 columns]\n",
      "ROR = 1.58 [95% CI 1.06, 2.38]\n",
      "PRR = 1.57 [95% CI 1.06, 2.33]\n",
      "RRR = 1.57 [95% CI 1.06, 2.33]\n",
      "HOR = 1.62 [95% CI 1.08, 2.42]\n",
      "Fisher p = 0.03728\n",
      "Chi-square p = 0.02457\n",
      "Chi-square (Yates) = 4.49, p = 0.03407\n",
      "Bayesian IC = 0.68 [95% CI -0.24, 1.60]\n",
      "Bayesian PRR median = 1.61, P(PRR>1) = 0.987\n",
      "Bayesian ROR median = 1.59, P(ROR>1) = 0.983\n",
      "Results and breakdown exported to FAERS_Rhopressa_vision_changes_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 9. Results and Excel Data Output\n",
    "# =============================\n",
    "results = {\n",
    "    'Database': 'FAERS',\n",
    "    'Drug(s)': \", \".join(drug_synonyms),\n",
    "    'Event(s)': \", \".join(event_synonyms),\n",
    "    'Start Quarter': f\"Q{start_year_q[1]} {start_year_q[0]}\",\n",
    "    'End Quarter': f\"Q{end_year_q[1]} {end_year_q[0]}\",\n",
    "    'A (Drug+Event)': A,\n",
    "    'B (Drug+No Event)': B,\n",
    "    'C (Event+No Drug)': C,\n",
    "    'D (Neither)': D,\n",
    "    'ROR': ROR,\n",
    "    'ROR 95% CI Lower': lower_CI,\n",
    "    'ROR 95% CI Upper': upper_CI,\n",
    "    'PRR': PRR,\n",
    "    'PRR 95% CI Lower': lower_CI_PRR,\n",
    "    'PRR 95% CI Upper': upper_CI_PRR,\n",
    "    'RRR': RRR,\n",
    "    'RRR 95% CI Lower': lower_CI_RRR,\n",
    "    'RRR 95% CI Upper': upper_CI_RRR,\n",
    "    'Haldane OR': HOR,\n",
    "    'Haldane OR 95% CI Lower': lower_CI_HOR,\n",
    "    'Haldane OR 95% CI Upper': upper_CI_HOR,\n",
    "    'Fisher p-value': p_fisher,\n",
    "    'Chi2 p-value': p_chi2,\n",
    "    'Chi2 Yates': chi2_yates,\n",
    "    'Chi2 Yates p-value': p_chi2_yates,\n",
    "    'Bayesian IC (log2)': IC,\n",
    "    'Bayesian IC 95% CI Lower': IC_low,\n",
    "    'Bayesian IC 95% CI Upper': IC_high,\n",
    "    'Bayesian PRR Mean': prr_bayes[\"mean\"],\n",
    "    'Bayesian PRR Median': prr_bayes[\"median\"],\n",
    "    'Bayesian PRR 95% CI Lower': prr_bayes[\"ci_low\"],\n",
    "    'Bayesian PRR 95% CI Upper': prr_bayes[\"ci_high\"],\n",
    "    'Bayesian PRR P(PRR>1)': prr_bayes[\"p_gt1\"],\n",
    "    'Bayesian ROR Mean': ror_bayes[\"mean\"],\n",
    "    'Bayesian ROR Median': ror_bayes[\"median\"],\n",
    "    'Bayesian ROR 95% CI Lower': ror_bayes[\"ci_low\"],\n",
    "    'Bayesian ROR 95% CI Upper': ror_bayes[\"ci_high\"],\n",
    "    'Bayesian ROR P(ROR>1)': ror_bayes[\"p_gt1\"],\n",
    "    'DRUG Duplicates Removed': duplicates_removed_drug,\n",
    "    'Original DRUG Records': df_drug_ps_before,\n",
    "    'Skipped Files': len(skipped_rows_log)\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame([results])\n",
    "print(result_df)\n",
    "\n",
    "print(f\"ROR = {ROR:.2f} [95% CI {lower_CI:.2f}, {upper_CI:.2f}]\")\n",
    "print(f\"PRR = {PRR:.2f} [95% CI {lower_CI_PRR:.2f}, {upper_CI_PRR:.2f}]\")\n",
    "print(f\"RRR = {RRR:.2f} [95% CI {lower_CI_RRR:.2f}, {upper_CI_RRR:.2f}]\")\n",
    "print(f\"HOR = {HOR:.2f} [95% CI {lower_CI_HOR:.2f}, {upper_CI_HOR:.2f}]\")\n",
    "print(f\"Fisher p = {p_fisher:.4g}\")\n",
    "print(f\"Chi-square p = {p_chi2:.4g}\")\n",
    "print(f\"Chi-square (Yates) = {chi2_yates:.2f}, p = {p_chi2_yates:.4g}\")\n",
    "print(f\"Bayesian IC = {IC:.2f} [95% CI {IC_low:.2f}, {IC_high:.2f}]\")\n",
    "print(f\"Bayesian PRR median = {prr_bayes['median']:.2f}, P(PRR>1) = {prr_bayes['p_gt1']:.3f}\")\n",
    "print(f\"Bayesian ROR median = {ror_bayes['median']:.2f}, P(ROR>1) = {ror_bayes['p_gt1']:.3f}\")\n",
    "\n",
    "with pd.ExcelWriter(output_file) as writer:\n",
    "    result_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "    breakdown_df.to_excel(writer, sheet_name='Event_Synonym_Breakdown', index=False)\n",
    "\n",
    "print(f\"Results and breakdown exported to {output_file}\")\n",
    "\n",
    "if skipped_rows_log:\n",
    "    pd.DataFrame(skipped_rows_log, columns=[\"File\", \"Error\"]).to_csv(csv_log_output, index=False)\n",
    "    print(\"Skipped file errors saved to 'skipped_files_log.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a428d0-595b-4870-b36e-502474d6aaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
